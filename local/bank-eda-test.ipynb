{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP7305 Assignment4 \n",
    "\n",
    "Basic Infomation:\n",
    "\n",
    "Dataset selected: Bank Marketing Dataset\n",
    "\n",
    "Kaggle link: https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset/data\n",
    "\n",
    "Source: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n",
    "\n",
    "Hint: This ipynb file is for local envrionment testing only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, format_number, count, when, floor, desc\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/03 11:10:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "  .builder\n",
    "  .appName(\"bank-eda\")\n",
    "  .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_file = \"bank.csv\"\n",
    "\n",
    "bank_df = (spark.read.format(\"csv\") \n",
    "  .option(\"header\", \"true\") \n",
    "  .option(\"inferSchema\", \"true\") \n",
    "  .load(bank_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 11162\n",
      "Number of columns: 17\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows: {bank_df.count()}\")\n",
    "print(f\"Number of columns: {len(bank_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Expolre whether the marriage will lead to debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------------------+\n",
      "| marital|avg_balance|      loan_yes_rate|\n",
      "+--------+-----------+-------------------+\n",
      "|divorced|   1,371.84| 0.1554524361948956|\n",
      "| married|   1,599.93| 0.1437568886789482|\n",
      "|  single|   1,457.26|0.09835133598635588|\n",
      "+--------+-----------+-------------------+\n",
      "\n",
      "Overall Loan Rate: 13.00%\n"
     ]
    }
   ],
   "source": [
    "loan_rate_by_marital = bank_df.groupBy(\"marital\").agg(\n",
    "    format_number(avg(\"balance\"), 2).alias(\"avg_balance\"),\n",
    "    (count(when(col(\"loan\") == \"yes\", True)) / count(\"*\")).alias(\"loan_yes_rate\")\n",
    ").orderBy(col(\"loan_yes_rate\").desc())\n",
    "\n",
    "loan_rate_by_marital.show()\n",
    "\n",
    "overall_loan_rate = round(\n",
    "    bank_df.where(col(\"loan\") == \"yes\").count() / bank_df.count(), 2\n",
    ")\n",
    "print(f\"Overall Loan Rate: {overall_loan_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['loan_yes_rate DESC NULLS LAST], true\n",
      "+- Aggregate [marital#19], [marital#19, format_number(avg(balance#22), 2) AS avg_balance#91, (cast(count(CASE WHEN (loan#24 = yes) THEN true END) as double) / cast(count(1) as double)) AS loan_yes_rate#94]\n",
      "   +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "marital: string, avg_balance: string, loan_yes_rate: double\n",
      "Sort [loan_yes_rate#94 DESC NULLS LAST], true\n",
      "+- Aggregate [marital#19], [marital#19, format_number(avg(balance#22), 2) AS avg_balance#91, (cast(count(CASE WHEN (loan#24 = yes) THEN true END) as double) / cast(count(1) as double)) AS loan_yes_rate#94]\n",
      "   +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [loan_yes_rate#94 DESC NULLS LAST], true\n",
      "+- Aggregate [marital#19], [marital#19, format_number(avg(balance#22), 2) AS avg_balance#91, (cast(count(CASE WHEN (loan#24 = yes) THEN true END) as double) / cast(count(1) as double)) AS loan_yes_rate#94]\n",
      "   +- Project [marital#19, balance#22, loan#24]\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [loan_yes_rate#94 DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(loan_yes_rate#94 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=304]\n",
      "      +- HashAggregate(keys=[marital#19], functions=[avg(balance#22), count(CASE WHEN (loan#24 = yes) THEN true END), count(1)], output=[marital#19, avg_balance#91, loan_yes_rate#94])\n",
      "         +- Exchange hashpartitioning(marital#19, 200), ENSURE_REQUIREMENTS, [plan_id=301]\n",
      "            +- HashAggregate(keys=[marital#19], functions=[partial_avg(balance#22), partial_count(CASE WHEN (loan#24 = yes) THEN true END), partial_count(1)], output=[marital#19, sum#112, count#113L, count#114L, count#115L])\n",
      "               +- FileScan csv [marital#19,balance#22,loan#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/frankleung/Documents/Docker/ass4test/bank.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<marital:string,balance:int,loan:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_rate_by_marital.write.csv(\"loan_rate_by_marital\", mode=\"overwrite\", header=True)\n",
    "loan_rate_by_marital.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check the loan rate and housing rate according to different kinds of jobs. And find those with higher housing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+--------------------+-------------------+\n",
      "|          job|avg_balance|       loan_yes_rate|   housing_yes_rate|\n",
      "+-------------+-----------+--------------------+-------------------+\n",
      "|  blue-collar|   1,203.93| 0.17335390946502058| 0.6795267489711934|\n",
      "|     services|   1,081.17|  0.1668472372697725| 0.6132177681473456|\n",
      "|       admin.|   1,195.87| 0.17691154422788605| 0.5547226386806596|\n",
      "| entrepreneur|   1,621.94| 0.21341463414634146| 0.5060975609756098|\n",
      "|   technician|   1,556.29| 0.13603949533735601| 0.4805266044980801|\n",
      "|self-employed|   1,865.37|  0.1382716049382716|0.42962962962962964|\n",
      "|   management|   1,793.66| 0.10132501948558068| 0.4181605611847233|\n",
      "|   unemployed|   1,314.72|0.058823529411764705| 0.3137254901960784|\n",
      "|    housemaid|   1,366.16|   0.072992700729927| 0.2773722627737226|\n",
      "|      retired|   2,417.25| 0.07069408740359898|0.15809768637532134|\n",
      "|      student|   1,500.78|0.002777777777777778|0.14166666666666666|\n",
      "|      unknown|   1,945.46| 0.02857142857142857|0.04285714285714286|\n",
      "+-------------+-----------+--------------------+-------------------+\n",
      "\n",
      "Overall Housing Rate: 47.00%\n"
     ]
    }
   ],
   "source": [
    "loan_rate_by_job = bank_df.groupBy(\"job\").agg(\n",
    "    format_number(avg(\"balance\"), 2).alias(\"avg_balance\"),\n",
    "    (count(when(col(\"loan\") == \"yes\", True)) / count(\"*\")).alias(\"loan_yes_rate\"),\n",
    "    (count(when(col(\"housing\") == \"yes\", True)) / count(\"*\")).alias(\"housing_yes_rate\")\n",
    ").orderBy(col(\"housing_yes_rate\").desc())\n",
    "\n",
    "loan_rate_by_job.show()\n",
    "\n",
    "overall_housing_rate = round(\n",
    "    bank_df.where(col(\"housing\") == \"yes\").count() / bank_df.count(), 2\n",
    ")\n",
    "print(f\"Overall Housing Rate: {overall_housing_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['housing_yes_rate DESC NULLS LAST], true\n",
      "+- Aggregate [job#18], [job#18, format_number(avg(balance#22), 2) AS avg_balance#210, (cast(count(CASE WHEN (loan#24 = yes) THEN true END) as double) / cast(count(1) as double)) AS loan_yes_rate#213, (cast(count(CASE WHEN (housing#23 = yes) THEN true END) as double) / cast(count(1) as double)) AS housing_yes_rate#216]\n",
      "   +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "job: string, avg_balance: string, loan_yes_rate: double, housing_yes_rate: double\n",
      "Sort [housing_yes_rate#216 DESC NULLS LAST], true\n",
      "+- Aggregate [job#18], [job#18, format_number(avg(balance#22), 2) AS avg_balance#210, (cast(count(CASE WHEN (loan#24 = yes) THEN true END) as double) / cast(count(1) as double)) AS loan_yes_rate#213, (cast(count(CASE WHEN (housing#23 = yes) THEN true END) as double) / cast(count(1) as double)) AS housing_yes_rate#216]\n",
      "   +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [housing_yes_rate#216 DESC NULLS LAST], true\n",
      "+- Aggregate [job#18], [job#18, format_number(avg(balance#22), 2) AS avg_balance#210, (cast(count(CASE WHEN (loan#24 = yes) THEN true END) as double) / cast(count(1) as double)) AS loan_yes_rate#213, (cast(count(CASE WHEN (housing#23 = yes) THEN true END) as double) / cast(count(1) as double)) AS housing_yes_rate#216]\n",
      "   +- Project [job#18, balance#22, housing#23, loan#24]\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [housing_yes_rate#216 DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(housing_yes_rate#216 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=561]\n",
      "      +- HashAggregate(keys=[job#18], functions=[avg(balance#22), count(CASE WHEN (loan#24 = yes) THEN true END), count(1), count(CASE WHEN (housing#23 = yes) THEN true END)], output=[job#18, avg_balance#210, loan_yes_rate#213, housing_yes_rate#216])\n",
      "         +- Exchange hashpartitioning(job#18, 200), ENSURE_REQUIREMENTS, [plan_id=558]\n",
      "            +- HashAggregate(keys=[job#18], functions=[partial_avg(balance#22), partial_count(CASE WHEN (loan#24 = yes) THEN true END), partial_count(1), partial_count(CASE WHEN (housing#23 = yes) THEN true END)], output=[job#18, sum#238, count#239L, count#240L, count#241L, count#242L])\n",
      "               +- FileScan csv [job#18,balance#22,housing#23,loan#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/frankleung/Documents/Docker/ass4test/bank.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<job:string,balance:int,housing:string,loan:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loan_rate_by_job.write.csv(\"loan_rate_by_job\", mode=\"overwrite\", header=True)\n",
    "loan_rate_by_job.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore the relationship between age groups and average deposits and show the housing rates of different age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------------+\n",
      "|age_group|avg_balance|       housing_rate|\n",
      "+---------+-----------+-------------------+\n",
      "|       60|   2,481.71| 0.1797520661157025|\n",
      "|       50|   1,798.21|  0.386737400530504|\n",
      "|       40|   1,483.56| 0.5235920852359208|\n",
      "|       30|   1,350.98| 0.5560444650301065|\n",
      "|       20|   1,183.98|0.44313725490196076|\n",
      "+---------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_balance_housing_stats = bank_df \\\n",
    "    .withColumn(\"age_group\", floor(col(\"age\") / 10) * 10) \\\n",
    "    .groupBy(\"age_group\") \\\n",
    "    .agg(\n",
    "        format_number(avg(\"balance\"), 2).alias(\"avg_balance\"),\n",
    "        avg(when(col(\"housing\") == \"yes\", 1).otherwise(0)).alias(\"housing_rate\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"avg_balance\").desc())\n",
    "\n",
    "\n",
    "age_balance_housing_stats \\\n",
    "    .where(col(\"age_group\").isin([20, 30, 40, 50, 60])) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['avg_balance DESC NULLS LAST], true\n",
      "+- Aggregate [age_group#329L], [age_group#329L, format_number(avg(balance#22), 2) AS avg_balance#367, avg(CASE WHEN (housing#23 = yes) THEN 1 ELSE 0 END) AS housing_rate#369]\n",
      "   +- Project [age#17, job#18, marital#19, education#20, default#21, balance#22, housing#23, loan#24, contact#25, day#26, month#27, duration#28, campaign#29, pdays#30, previous#31, poutcome#32, deposit#33, (FLOOR((cast(age#17 as double) / cast(10 as double))) * cast(10 as bigint)) AS age_group#329L]\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "age_group: bigint, avg_balance: string, housing_rate: double\n",
      "Sort [avg_balance#367 DESC NULLS LAST], true\n",
      "+- Aggregate [age_group#329L], [age_group#329L, format_number(avg(balance#22), 2) AS avg_balance#367, avg(CASE WHEN (housing#23 = yes) THEN 1 ELSE 0 END) AS housing_rate#369]\n",
      "   +- Project [age#17, job#18, marital#19, education#20, default#21, balance#22, housing#23, loan#24, contact#25, day#26, month#27, duration#28, campaign#29, pdays#30, previous#31, poutcome#32, deposit#33, (FLOOR((cast(age#17 as double) / cast(10 as double))) * cast(10 as bigint)) AS age_group#329L]\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [avg_balance#367 DESC NULLS LAST], true\n",
      "+- Aggregate [age_group#329L], [age_group#329L, format_number(avg(balance#22), 2) AS avg_balance#367, avg(CASE WHEN (housing#23 = yes) THEN 1 ELSE 0 END) AS housing_rate#369]\n",
      "   +- Project [balance#22, housing#23, (FLOOR((cast(age#17 as double) / 10.0)) * 10) AS age_group#329L]\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [avg_balance#367 DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(avg_balance#367 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=767]\n",
      "      +- HashAggregate(keys=[age_group#329L], functions=[avg(balance#22), avg(CASE WHEN (housing#23 = yes) THEN 1 ELSE 0 END)], output=[age_group#329L, avg_balance#367, housing_rate#369])\n",
      "         +- Exchange hashpartitioning(age_group#329L, 200), ENSURE_REQUIREMENTS, [plan_id=764]\n",
      "            +- HashAggregate(keys=[age_group#329L], functions=[partial_avg(balance#22), partial_avg(CASE WHEN (housing#23 = yes) THEN 1 ELSE 0 END)], output=[age_group#329L, sum#386, count#387L, sum#388, count#389L])\n",
      "               +- Project [balance#22, housing#23, (FLOOR((cast(age#17 as double) / 10.0)) * 10) AS age_group#329L]\n",
      "                  +- FileScan csv [age#17,balance#22,housing#23] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/frankleung/Documents/Docker/ass4test/bank.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<age:int,balance:int,housing:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_balance_housing_stats.write.csv(\"age_balance_housing_stats\", mode=\"overwrite\", header=True)\n",
    "age_balance_housing_stats.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Education stat including the distribution of the education situation, the avg balance and housing rate of each education option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------+-------------------+\n",
      "|education|count|avg_balance|       housing_rate|\n",
      "+---------+-----+-----------+-------------------+\n",
      "| tertiary| 3689|   1,845.87| 0.3914339929520195|\n",
      "|  primary| 1500|   1,523.03|0.49466666666666664|\n",
      "|secondary| 5476|   1,296.48|  0.533418553688824|\n",
      "+---------+-----+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edu_stats = bank_df.where(col(\"education\") != \"unknown\") \\\n",
    "                  .groupBy(\"education\") \\\n",
    "                  .agg(count(\"*\").alias(\"count\"),\n",
    "                       format_number(avg(\"balance\"), 2).alias(\"avg_balance\"),\n",
    "                       (count(when(col(\"housing\") == \"yes\", True)) / count(\"*\")).alias(\"housing_rate\")) \\\n",
    "                  .orderBy(desc(\"avg_balance\"), desc(\"housing_rate\"))\n",
    "\n",
    "edu_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['avg_balance DESC NULLS LAST, 'housing_rate DESC NULLS LAST], true\n",
      "+- Aggregate [education#20], [education#20, count(1) AS count#445L, format_number(avg(balance#22), 2) AS avg_balance#447, (cast(count(CASE WHEN (housing#23 = yes) THEN true END) as double) / cast(count(1) as double)) AS housing_rate#450]\n",
      "   +- Filter NOT (education#20 = unknown)\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "education: string, count: bigint, avg_balance: string, housing_rate: double\n",
      "Sort [avg_balance#447 DESC NULLS LAST, housing_rate#450 DESC NULLS LAST], true\n",
      "+- Aggregate [education#20], [education#20, count(1) AS count#445L, format_number(avg(balance#22), 2) AS avg_balance#447, (cast(count(CASE WHEN (housing#23 = yes) THEN true END) as double) / cast(count(1) as double)) AS housing_rate#450]\n",
      "   +- Filter NOT (education#20 = unknown)\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [avg_balance#447 DESC NULLS LAST, housing_rate#450 DESC NULLS LAST], true\n",
      "+- Aggregate [education#20], [education#20, count(1) AS count#445L, format_number(avg(balance#22), 2) AS avg_balance#447, (cast(count(CASE WHEN (housing#23 = yes) THEN true END) as double) / cast(count(1) as double)) AS housing_rate#450]\n",
      "   +- Project [education#20, balance#22, housing#23]\n",
      "      +- Filter (isnotnull(education#20) AND NOT (education#20 = unknown))\n",
      "         +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [avg_balance#447 DESC NULLS LAST, housing_rate#450 DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(avg_balance#447 DESC NULLS LAST, housing_rate#450 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=983]\n",
      "      +- HashAggregate(keys=[education#20], functions=[count(1), avg(balance#22), count(CASE WHEN (housing#23 = yes) THEN true END)], output=[education#20, count#445L, avg_balance#447, housing_rate#450])\n",
      "         +- Exchange hashpartitioning(education#20, 200), ENSURE_REQUIREMENTS, [plan_id=980]\n",
      "            +- HashAggregate(keys=[education#20], functions=[partial_count(1), partial_avg(balance#22), partial_count(CASE WHEN (housing#23 = yes) THEN true END)], output=[education#20, count#471L, sum#472, count#473L, count#474L])\n",
      "               +- Filter (isnotnull(education#20) AND NOT (education#20 = unknown))\n",
      "                  +- FileScan csv [education#20,balance#22,housing#23] Batched: false, DataFilters: [isnotnull(education#20), NOT (education#20 = unknown)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/frankleung/Documents/Docker/ass4test/bank.csv], PartitionFilters: [], PushedFilters: [IsNotNull(education), Not(EqualTo(education,unknown))], ReadSchema: struct<education:string,balance:int,housing:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edu_stats.write.csv(\"edu_stats\", mode=\"overwrite\", header=True)\n",
    "edu_stats.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find those with higher posibility of default according to jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+-----------------+-----------+--------------------+\n",
      "|          job|default_count|non_default_count|total_count|        default_rate|\n",
      "+-------------+-------------+-----------------+-----------+--------------------+\n",
      "| entrepreneur|           10|              318|        328| 0.03048780487804878|\n",
      "|    housemaid|            8|              266|        274|0.029197080291970802|\n",
      "|   unemployed|            8|              349|        357|0.022408963585434174|\n",
      "|  blue-collar|           41|             1903|       1944| 0.02109053497942387|\n",
      "|self-employed|            8|              397|        405|0.019753086419753086|\n",
      "|   technician|           29|             1794|       1823|0.015907844212835986|\n",
      "|   management|           39|             2527|       2566|0.015198752922837101|\n",
      "|      unknown|            1|               69|         70|0.014285714285714285|\n",
      "|       admin.|           11|             1323|       1334|0.008245877061469266|\n",
      "|     services|            7|              916|        923|0.007583965330444204|\n",
      "|      retired|            5|              773|        778|0.006426735218508998|\n",
      "|      student|            1|              359|        360|0.002777777777777778|\n",
      "+-------------+-------------+-----------------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_default = bank_df.groupBy(\n",
    "    \"job\"\n",
    ").agg(\n",
    "    count(when(col(\"default\") == \"yes\", True)).alias(\"default_count\"),\n",
    "    count(when(col(\"default\") == \"no\", True)).alias(\"non_default_count\"),\n",
    "    count(\"*\").alias(\"total_count\")\n",
    ").withColumn(\n",
    "    \"default_rate\", col(\"default_count\") / col(\"total_count\")\n",
    ").orderBy(desc(\"default_rate\"))\n",
    "\n",
    "job_default.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=34872Kb max_used=34886Kb free=96199Kb\n",
      " bounds [0x00000001069e0000, 0x0000000108c30000, 0x000000010e9e0000]\n",
      " total_blobs=12776 nmethods=11780 adapters=908\n",
      " compilation: disabled (not enough contiguous free space left)\n",
      "== Parsed Logical Plan ==\n",
      "'Sort ['default_rate DESC NULLS LAST], true\n",
      "+- Project [job#18, default_count#526L, non_default_count#528L, total_count#530L, (cast(default_count#526L as double) / cast(total_count#530L as double)) AS default_rate#535]\n",
      "   +- Aggregate [job#18], [job#18, count(CASE WHEN (default#21 = yes) THEN true END) AS default_count#526L, count(CASE WHEN (default#21 = no) THEN true END) AS non_default_count#528L, count(1) AS total_count#530L]\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "job: string, default_count: bigint, non_default_count: bigint, total_count: bigint, default_rate: double\n",
      "Sort [default_rate#535 DESC NULLS LAST], true\n",
      "+- Project [job#18, default_count#526L, non_default_count#528L, total_count#530L, (cast(default_count#526L as double) / cast(total_count#530L as double)) AS default_rate#535]\n",
      "   +- Aggregate [job#18], [job#18, count(CASE WHEN (default#21 = yes) THEN true END) AS default_count#526L, count(CASE WHEN (default#21 = no) THEN true END) AS non_default_count#528L, count(1) AS total_count#530L]\n",
      "      +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [default_rate#535 DESC NULLS LAST], true\n",
      "+- Project [job#18, default_count#526L, non_default_count#528L, total_count#530L, (cast(default_count#526L as double) / cast(total_count#530L as double)) AS default_rate#535]\n",
      "   +- Aggregate [job#18], [job#18, count(CASE WHEN (default#21 = yes) THEN true END) AS default_count#526L, count(CASE WHEN (default#21 = no) THEN true END) AS non_default_count#528L, count(1) AS total_count#530L]\n",
      "      +- Project [job#18, default#21]\n",
      "         +- Relation [age#17,job#18,marital#19,education#20,default#21,balance#22,housing#23,loan#24,contact#25,day#26,month#27,duration#28,campaign#29,pdays#30,previous#31,poutcome#32,deposit#33] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [default_rate#535 DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(default_rate#535 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=1199]\n",
      "      +- Project [job#18, default_count#526L, non_default_count#528L, total_count#530L, (cast(default_count#526L as double) / cast(total_count#530L as double)) AS default_rate#535]\n",
      "         +- HashAggregate(keys=[job#18], functions=[count(CASE WHEN (default#21 = yes) THEN true END), count(CASE WHEN (default#21 = no) THEN true END), count(1)], output=[job#18, default_count#526L, non_default_count#528L, total_count#530L])\n",
      "            +- Exchange hashpartitioning(job#18, 200), ENSURE_REQUIREMENTS, [plan_id=1195]\n",
      "               +- HashAggregate(keys=[job#18], functions=[partial_count(CASE WHEN (default#21 = yes) THEN true END), partial_count(CASE WHEN (default#21 = no) THEN true END), partial_count(1)], output=[job#18, count#559L, count#560L, count#561L])\n",
      "                  +- FileScan csv [job#18,default#21] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/Users/frankleung/Documents/Docker/ass4test/bank.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<job:string,default:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_default.write.csv(\"job_default\", mode=\"overwrite\", header=True)\n",
    "job_default.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
